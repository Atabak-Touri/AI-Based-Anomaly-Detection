{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28263a3-3a11-4eeb-8433-9774078fe510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Function to read data from text (CSV) files\n",
    "def read_data(file_name):\n",
    "    df = pd.read_csv(file_name, names=['data_id', 'accel0X', 'accel0Y', 'accel0Z', 'accel1X', 'accel1Y', 'accel1Z', 'tension', 'timestamp'], dtype=str)\n",
    "    df['time'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df[['accel0X', 'accel0Y', 'accel0Z', 'accel1X', 'accel1Y', 'accel1Z', 'tension']] = df[['accel0X', 'accel0Y', 'accel0Z', 'accel1X', 'accel1Y', 'accel1Z', 'tension']].apply(pd.to_numeric, errors='coerce')\n",
    "    df['tension'] = 0.650 * (df['tension'] - 2166)\n",
    "    return df\n",
    "\n",
    "def establish_printing_start(file_name):\n",
    "    df = pd.read_json(file_name, lines=True)\n",
    "    df = json_normalize(df.to_dict('records'))\n",
    "    return df[df.status == 'P'].head(1)['timestamp'].values[0]\n",
    "\n",
    "# Add Label Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "def process_and_label_data(base_dir):\n",
    "    categories = ['arm_failure', 'bowden', 'plastic', 'proper', 'retraction_05', 'unstick']\n",
    "    all_data = []\n",
    "\n",
    "    for category in categories:\n",
    "        txt_file = os.path.join(base_dir, category, 't.txt')\n",
    "        json_file = os.path.join(base_dir, category, 'j.json')\n",
    "\n",
    "        df = read_data(txt_file)\n",
    "        start_time = establish_printing_start(json_file)\n",
    "        df = df[df.time > start_time]\n",
    "        \n",
    "        # Add category label\n",
    "        df['label'] = category\n",
    "\n",
    "        all_data.append(df)\n",
    "\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "def zscore_normalize_data(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].astype(float)\n",
    "        mean = df[column].mean()\n",
    "        std = df[column].std()\n",
    "        df[column] = (df[column] - mean) / std\n",
    "    return df\n",
    "\n",
    "def create_1d_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Call the function to process and label the data\n",
    "base_directory = r'C:\\MyFiles\\AI\\UNI\\ML-DP-AI\\Project\\dataset\\WithBase'\n",
    "all_data = process_and_label_data(base_directory)\n",
    "\n",
    "# Handle missing values using interpolation\n",
    "all_data_int = all_data.interpolate(method='linear')\n",
    "\n",
    "# Normalize the features\n",
    "features = ['accel0X', 'accel0Y', 'accel0Z', 'accel1X', 'accel1Y', 'accel1Z', 'tension']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef1f4a8f-fb76-48da-829b-56839306aad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy with all features: 0.9635\n",
      "Test Accuracy without accel0X: 0.9459\n",
      "Test Accuracy without accel0Y: 0.9406\n",
      "Test Accuracy without accel0Z: 0.9314\n",
      "Test Accuracy without accel1X: 0.9594\n",
      "Test Accuracy without accel1Y: 0.9574\n",
      "Test Accuracy without accel1Z: 0.9582\n",
      "Test Accuracy without tension: 0.9429\n",
      "\n",
      "Feature Impact:\n",
      "accel0Z: 0.0320 drop in accuracy\n",
      "accel0Y: 0.0229 drop in accuracy\n",
      "tension: 0.0205 drop in accuracy\n",
      "accel0X: 0.0176 drop in accuracy\n",
      "accel1Y: 0.0061 drop in accuracy\n",
      "accel1Z: 0.0053 drop in accuracy\n",
      "accel1X: 0.0041 drop in accuracy\n"
     ]
    }
   ],
   "source": [
    "# This cell removes only one feature\n",
    "# This cell removes only one feature\n",
    "# This cell removes only one feature\n",
    "# This cell removes only one feature\n",
    "# This cell removes only one feature\n",
    "# This cell removes only one feature\n",
    "\n",
    "def run_experiment1(features_to_use):\n",
    "    # Clone and preprocess data for a new experiment\n",
    "    data = all_data_int.copy()\n",
    "    data = zscore_normalize_data(data, features_to_use)\n",
    "    \n",
    "    # Reshape data into segments\n",
    "    X = data[features_to_use].values\n",
    "    y = data['label'].values\n",
    "\n",
    "    time_steps = 100\n",
    "    samples = len(X) // time_steps\n",
    "    X = X[:samples * time_steps].reshape(samples, time_steps, len(features_to_use))\n",
    "\n",
    "    # Encode categorical labels\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    y = y[:samples * time_steps].reshape(samples, time_steps, -1)\n",
    "    y = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=y)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create the model\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    num_classes = len(np.unique(y))\n",
    "    model = create_1d_cnn_model(input_shape, num_classes)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_accuracy\n",
    "\n",
    "# Evaluate the baseline model with all features\n",
    "baseline_accuracy = run_experiment1(features)\n",
    "print(f'Baseline Test Accuracy with all features: {baseline_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the effect of each feature\n",
    "results1 = {}\n",
    "for feature in features:\n",
    "    features_to_use = [f for f in features if f != feature]\n",
    "    test_accuracy = run_experiment1(features_to_use)\n",
    "    results1[feature] = test_accuracy\n",
    "    print(f'Test Accuracy without {feature}: {test_accuracy:.4f}')\n",
    "\n",
    "# Display a sorted list of feature importances\n",
    "print(\"\\nFeature Impact:\")\n",
    "for feature, accuracy in sorted(results1.items(), key=lambda item: baseline_accuracy - item[1], reverse=True):\n",
    "    print(f\"{feature}: {baseline_accuracy - accuracy:.4f} drop in accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c077cbc2-57a8-452b-855d-ddbf96b84e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy with all features: 0.9647\n",
      "Test Accuracy with only accel0X: 0.6431\n",
      "Test Accuracy with only accel0Y: 0.7066\n",
      "Test Accuracy with only accel0Z: 0.6281\n",
      "Test Accuracy with only accel1X: 0.5546\n",
      "Test Accuracy with only accel1Y: 0.6022\n",
      "Test Accuracy with only accel1Z: 0.5558\n",
      "Test Accuracy with only tension: 0.5954\n",
      "\n",
      "Feature Impact:\n",
      "accel1X: 0.4101 drop in accuracy\n",
      "accel1Z: 0.4089 drop in accuracy\n",
      "tension: 0.3692 drop in accuracy\n",
      "accel1Y: 0.3625 drop in accuracy\n",
      "accel0Z: 0.3366 drop in accuracy\n",
      "accel0X: 0.3216 drop in accuracy\n",
      "accel0Y: 0.2581 drop in accuracy\n"
     ]
    }
   ],
   "source": [
    "# This cell uses only one feature\n",
    "# This cell uses only one feature\n",
    "# This cell uses only one feature\n",
    "# This cell uses only one feature\n",
    "# This cell uses only one feature\n",
    "# This cell uses only one feature\n",
    "# This cell uses only one feature\n",
    "# This cell uses only one feature\n",
    "\n",
    "def run_experiment2(features_to_use):\n",
    "    # Clone and preprocess data for a new experiment\n",
    "    data = all_data_int.copy()\n",
    "    data = zscore_normalize_data(data, features_to_use)\n",
    "    \n",
    "    # Reshape data into segments\n",
    "    X = data[features_to_use].values\n",
    "    y = data['label'].values\n",
    "\n",
    "    time_steps = 100\n",
    "    samples = len(X) // time_steps\n",
    "    X = X[:samples * time_steps].reshape(samples, time_steps, len(features_to_use))\n",
    "\n",
    "    # Encode categorical labels\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    y = y[:samples * time_steps].reshape(samples, time_steps, -1)\n",
    "    y = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=y)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create the model\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    num_classes = len(np.unique(y))\n",
    "    model = create_1d_cnn_model(input_shape, num_classes)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_accuracy\n",
    "\n",
    "# Evaluate the baseline model with all features\n",
    "baseline_accuracy = run_experiment2(features)\n",
    "print(f'Baseline Test Accuracy with all features: {baseline_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the effect of each feature\n",
    "results2 = {}\n",
    "for feature in features:\n",
    "    features_to_use = [f for f in features if f == feature]\n",
    "    test_accuracy = run_experiment2(features_to_use)\n",
    "    results2[feature] = test_accuracy\n",
    "    print(f'Test Accuracy with only {feature}: {test_accuracy:.4f}')\n",
    "\n",
    "# Display a sorted list of feature importances\n",
    "print(\"\\nFeature Impact:\")\n",
    "for feature, accuracy in sorted(results2.items(), key=lambda item: baseline_accuracy - item[1], reverse=True):\n",
    "    print(f\"{feature}: {baseline_accuracy - accuracy:.4f} drop in accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bc31c-9616-4e68-b600-afb2608f05e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2167bb-55e6-4cbe-b655-8312c50df48a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27411f24-e767-4ed9-9872-0c7794c20847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy with all features: 0.9677\n",
      "Test Accuracy without ['accel1Z', 'accel0Z']: 0.9127\n",
      "Test Accuracy without ['accel1X', 'tension']: 0.9337\n",
      "Test Accuracy without ['accel0Z', 'accel1X']: 0.9164\n",
      "Test Accuracy without ['accel1X', 'accel0X']: 0.9404\n",
      "Test Accuracy without ['accel1X', 'tension']: 0.9365\n",
      "\n",
      "Feature Impact:\n",
      "Removed ('accel1Z', 'accel0Z'): 0.0550 drop in accuracy\n",
      "Removed ('accel0Z', 'accel1X'): 0.0513 drop in accuracy\n",
      "Removed ('accel1X', 'tension'): 0.0313 drop in accuracy\n",
      "Removed ('accel1X', 'accel0X'): 0.0273 drop in accuracy\n"
     ]
    }
   ],
   "source": [
    "# This cell removes two features\n",
    "# This cell removes two features\n",
    "# This cell removes two features\n",
    "# This cell removes two features\n",
    "# This cell removes two features\n",
    "# This cell removes two features\n",
    "\n",
    "import random\n",
    "def run_experiment3(features_to_use):\n",
    "    # Clone and preprocess data for a new experiment\n",
    "    data = all_data_int.copy()\n",
    "    data = zscore_normalize_data(data, features_to_use)\n",
    "    \n",
    "    # Reshape data into segments\n",
    "    X = data[features_to_use].values\n",
    "    y = data['label'].values\n",
    "\n",
    "    time_steps = 100\n",
    "    samples = len(X) // time_steps\n",
    "    X = X[:samples * time_steps].reshape(samples, time_steps, len(features_to_use))\n",
    "\n",
    "    # Encode categorical labels\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    y = y[:samples * time_steps].reshape(samples, time_steps, -1)\n",
    "    y = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=y)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create the model\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    num_classes = len(np.unique(y))\n",
    "    model = create_1d_cnn_model(input_shape, num_classes)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_accuracy\n",
    "\n",
    "# Evaluate the baseline model with all features\n",
    "baseline_accuracy = run_experiment3(features)\n",
    "print(f'Baseline Test Accuracy with all features: {baseline_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the effect of removing two features at a time for 5 trials\n",
    "trials = 5\n",
    "results3 = {}\n",
    "for i in range(trials):\n",
    "    features_to_remove = random.sample(features, 2)\n",
    "    features_to_use = [f for f in features if f not in features_to_remove]\n",
    "    test_accuracy = run_experiment3(features_to_use)\n",
    "    results3[tuple(features_to_remove)] = test_accuracy\n",
    "    print(f'Test Accuracy without {features_to_remove}: {test_accuracy:.4f}')\n",
    "\n",
    "# Display a sorted list of feature importances\n",
    "print(\"\\nFeature Impact:\")\n",
    "for features_removed, accuracy in sorted(results3.items(), key=lambda item: baseline_accuracy - item[1], reverse=True):\n",
    "    print(f\"Removed {features_removed}: {baseline_accuracy - accuracy:.4f} drop in accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d19f47e0-084f-4edc-9566-2b5ad9e8570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy with all features: 0.9612\n",
      "Test Accuracy without ['accel0X', 'accel0Z', 'accel0Y']: 0.7660\n",
      "Test Accuracy without ['accel0X', 'accel1Y', 'accel1X']: 0.9404\n",
      "Test Accuracy without ['accel1X', 'accel0X', 'accel1Y']: 0.9425\n",
      "Test Accuracy without ['accel1X', 'tension', 'accel0Z']: 0.8855\n",
      "Test Accuracy without ['accel1X', 'tension', 'accel0X']: 0.9172\n",
      "\n",
      "Feature Impact:\n",
      "Removed ('accel0X', 'accel0Z', 'accel0Y'): 0.1952 drop in accuracy\n",
      "Removed ('accel1X', 'tension', 'accel0Z'): 0.0758 drop in accuracy\n",
      "Removed ('accel1X', 'tension', 'accel0X'): 0.0441 drop in accuracy\n",
      "Removed ('accel0X', 'accel1Y', 'accel1X'): 0.0209 drop in accuracy\n",
      "Removed ('accel1X', 'accel0X', 'accel1Y'): 0.0187 drop in accuracy\n"
     ]
    }
   ],
   "source": [
    "# This cell removes three features\n",
    "# This cell removes three features\n",
    "# This cell removes three features\n",
    "# This cell removes three features\n",
    "# This cell removes three features\n",
    "# This cell removes three features\n",
    "# This cell removes three features\n",
    "\n",
    "def run_experiment4(features_to_use):\n",
    "    # Clone and preprocess data for a new experiment\n",
    "    data = all_data_int.copy()\n",
    "    data = zscore_normalize_data(data, features_to_use)\n",
    "    \n",
    "    # Reshape data into segments\n",
    "    X = data[features_to_use].values\n",
    "    y = data['label'].values\n",
    "\n",
    "    time_steps = 100\n",
    "    samples = len(X) // time_steps\n",
    "    X = X[:samples * time_steps].reshape(samples, time_steps, len(features_to_use))\n",
    "\n",
    "    # Encode categorical labels\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    y = y[:samples * time_steps].reshape(samples, time_steps, -1)\n",
    "    y = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=y)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create the model\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    num_classes = len(np.unique(y))\n",
    "    model = create_1d_cnn_model(input_shape, num_classes)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_accuracy\n",
    "\n",
    "# Evaluate the baseline model with all features\n",
    "baseline_accuracy = run_experiment4(features)\n",
    "print(f'Baseline Test Accuracy with all features: {baseline_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the effect of removing three features at a time for 5 trials\n",
    "trials = 5\n",
    "results4 = {}\n",
    "for i in range(trials):\n",
    "    features_to_remove = random.sample(features, 3)\n",
    "    features_to_use = [f for f in features if f not in features_to_remove]\n",
    "    test_accuracy = run_experiment4(features_to_use)\n",
    "    results4[tuple(features_to_remove)] = test_accuracy\n",
    "    print(f'Test Accuracy without {features_to_remove}: {test_accuracy:.4f}')\n",
    "\n",
    "# Display a sorted list of feature importances\n",
    "print(\"\\nFeature Impact:\")\n",
    "for features_removed, accuracy in sorted(results4.items(), key=lambda item: baseline_accuracy - item[1], reverse=True):\n",
    "    print(f\"Removed {features_removed}: {baseline_accuracy - accuracy:.4f} drop in accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706617f6-e3b3-4905-807c-78877ac99ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy with all features: 0.9635\n",
      "Test Accuracy without ['accel1X', 'accel0Z', 'accel1Z', 'accel1Y']: 0.9149\n",
      "Test Accuracy without ['accel0X', 'accel0Z', 'accel1X', 'accel1Y']: 0.8688\n",
      "Test Accuracy without ['accel1Y', 'accel0Y', 'tension', 'accel1X']: 0.8774\n",
      "Test Accuracy without ['accel1Z', 'accel0Y', 'accel1Y', 'accel0X']: 0.7681\n",
      "Test Accuracy without ['accel0X', 'accel1Y', 'accel0Y', 'accel1X']: 0.7825\n",
      "\n",
      "Feature Impact:\n",
      "Removed ('accel1Z', 'accel0Y', 'accel1Y', 'accel0X'): 0.1954 drop in accuracy\n",
      "Removed ('accel0X', 'accel1Y', 'accel0Y', 'accel1X'): 0.1809 drop in accuracy\n",
      "Removed ('accel0X', 'accel0Z', 'accel1X', 'accel1Y'): 0.0947 drop in accuracy\n",
      "Removed ('accel1Y', 'accel0Y', 'tension', 'accel1X'): 0.0861 drop in accuracy\n",
      "Removed ('accel1X', 'accel0Z', 'accel1Z', 'accel1Y'): 0.0486 drop in accuracy\n"
     ]
    }
   ],
   "source": [
    "# This cell removes four features\n",
    "# This cell removes four features\n",
    "# This cell removes four features\n",
    "# This cell removes four features\n",
    "# This cell removes four features\n",
    "# This cell removes four features\n",
    "\n",
    "\n",
    "import random\n",
    "def run_experiment5(features_to_use):\n",
    "    # Clone and preprocess data for a new experiment\n",
    "    data = all_data_int.copy()\n",
    "    data = zscore_normalize_data(data, features_to_use)\n",
    "    \n",
    "    # Reshape data into segments\n",
    "    X = data[features_to_use].values\n",
    "    y = data['label'].values\n",
    "\n",
    "    time_steps = 100\n",
    "    samples = len(X) // time_steps\n",
    "    X = X[:samples * time_steps].reshape(samples, time_steps, len(features_to_use))\n",
    "\n",
    "    # Encode categorical labels\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    y = y[:samples * time_steps].reshape(samples, time_steps, -1)\n",
    "    y = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=y)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create the model\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    num_classes = len(np.unique(y))\n",
    "    model = create_1d_cnn_model(input_shape, num_classes)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_accuracy\n",
    "\n",
    "# Evaluate the baseline model with all features\n",
    "baseline_accuracy = run_experiment5(features)\n",
    "print(f'Baseline Test Accuracy with all features: {baseline_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the effect of removing three features at a time for 5 trials\n",
    "trials = 5\n",
    "results5 = {}\n",
    "for i in range(trials):\n",
    "    features_to_remove = random.sample(features, 4)\n",
    "    features_to_use = [f for f in features if f not in features_to_remove]\n",
    "    test_accuracy = run_experiment5(features_to_use)\n",
    "    results5[tuple(features_to_remove)] = test_accuracy\n",
    "    print(f'Test Accuracy without {features_to_remove}: {test_accuracy:.4f}')\n",
    "\n",
    "# Display a sorted list of feature importances\n",
    "print(\"\\nFeature Impact:\")\n",
    "for features_removed, accuracy in sorted(results5.items(), key=lambda item: baseline_accuracy - item[1], reverse=True):\n",
    "    print(f\"Removed {features_removed}: {baseline_accuracy - accuracy:.4f} drop in accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b08984da-1f1d-4212-8bf8-9385fee7fa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy with all features: 0.9616\n",
      "Test Accuracy without ['accel0X', 'accel1Y', 'accel1Z', 'accel0Y', 'accel1X']: 0.7631\n",
      "Test Accuracy without ['accel1Y', 'accel0Y', 'tension', 'accel0Z', 'accel0X']: 0.6160\n",
      "Test Accuracy without ['accel1X', 'accel0Y', 'accel0X', 'accel0Z', 'tension']: 0.6863\n",
      "Test Accuracy without ['accel1Y', 'accel0Y', 'tension', 'accel1X', 'accel1Z']: 0.8498\n",
      "Test Accuracy without ['accel1Z', 'accel1Y', 'accel0Z', 'tension', 'accel0Y']: 0.7213\n",
      "\n",
      "Feature Impact:\n",
      "Removed ('accel1Y', 'accel0Y', 'tension', 'accel0Z', 'accel0X'): 0.3456 drop in accuracy\n",
      "Removed ('accel1X', 'accel0Y', 'accel0X', 'accel0Z', 'tension'): 0.2752 drop in accuracy\n",
      "Removed ('accel1Z', 'accel1Y', 'accel0Z', 'tension', 'accel0Y'): 0.2402 drop in accuracy\n",
      "Removed ('accel0X', 'accel1Y', 'accel1Z', 'accel0Y', 'accel1X'): 0.1984 drop in accuracy\n",
      "Removed ('accel1Y', 'accel0Y', 'tension', 'accel1X', 'accel1Z'): 0.1118 drop in accuracy\n"
     ]
    }
   ],
   "source": [
    "# This cell removes five features\n",
    "# This cell removes five features\n",
    "# This cell removes five features\n",
    "# This cell removes five features\n",
    "# This cell removes five features\n",
    "# This cell removes five features\n",
    "# This cell removes five features\n",
    "\n",
    "import random\n",
    "def run_experiment6(features_to_use):\n",
    "    # Clone and preprocess data for a new experiment\n",
    "    data = all_data_int.copy()\n",
    "    data = zscore_normalize_data(data, features_to_use)\n",
    "    \n",
    "    # Reshape data into segments\n",
    "    X = data[features_to_use].values\n",
    "    y = data['label'].values\n",
    "\n",
    "    time_steps = 100\n",
    "    samples = len(X) // time_steps\n",
    "    X = X[:samples * time_steps].reshape(samples, time_steps, len(features_to_use))\n",
    "\n",
    "    # Encode categorical labels\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    y = y[:samples * time_steps].reshape(samples, time_steps, -1)\n",
    "    y = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=y)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create the model\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    num_classes = len(np.unique(y))\n",
    "    model = create_1d_cnn_model(input_shape, num_classes)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_accuracy\n",
    "\n",
    "# Evaluate the baseline model with all features\n",
    "baseline_accuracy = run_experiment6(features)\n",
    "print(f'Baseline Test Accuracy with all features: {baseline_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the effect of removing three features at a time for 5 trials\n",
    "trials = 5\n",
    "results6 = {}\n",
    "for i in range(trials):\n",
    "    features_to_remove = random.sample(features, 5)\n",
    "    features_to_use = [f for f in features if f not in features_to_remove]\n",
    "    test_accuracy = run_experiment6(features_to_use)\n",
    "    results6[tuple(features_to_remove)] = test_accuracy\n",
    "    print(f'Test Accuracy without {features_to_remove}: {test_accuracy:.4f}')\n",
    "\n",
    "# Display a sorted list of feature importances\n",
    "print(\"\\nFeature Impact:\")\n",
    "for features_removed, accuracy in sorted(results6.items(), key=lambda item: baseline_accuracy - item[1], reverse=True):\n",
    "    print(f\"Removed {features_removed}: {baseline_accuracy - accuracy:.4f} drop in accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e1027-79e0-41a5-a780-26951f2ee8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edee7a9-c0d1-4b94-b927-ffda200c2b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8684c84-c64f-406c-923c-202996bda99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ef107-fa42-4835-86e9-61cd3740b743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66146a51-e2a9-4df3-812b-c6999bd837ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6405fc-04ef-4b7d-956c-f35bf0b359c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
